{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1b79ad0-9b15-4170-b143-720cd22a25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "import random\n",
    "\n",
    "#Pillow\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import  train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed536ac6-03cb-4777-9032-ef339fa64a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf5a3065-9156-4b4a-b18f-03e33ce95e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Overview\n",
    "classes = { 0:'Speed limit (20km/h)',\n",
    "            1:'Speed limit (30km/h)', \n",
    "            2:'Speed limit (50km/h)', \n",
    "            3:'Speed limit (60km/h)', \n",
    "            4:'Speed limit (70km/h)', \n",
    "            5:'Speed limit (80km/h)', \n",
    "            6:'End of speed limit (80km/h)', \n",
    "            7:'Speed limit (100km/h)', \n",
    "            8:'Speed limit (120km/h)', \n",
    "            9:'No passing', \n",
    "            10:'No passing veh over 3.5 tons', \n",
    "            11:'Right-of-way at intersection', \n",
    "            12:'Priority road', \n",
    "            13:'Yield', \n",
    "            14:'Stop', \n",
    "            15:'No vehicles', \n",
    "            16:'Veh > 3.5 tons prohibited', \n",
    "            17:'No entry', \n",
    "            18:'General caution', \n",
    "            19:'Dangerous curve left', \n",
    "            20:'Dangerous curve right', \n",
    "            21:'Double curve', \n",
    "            22:'Bumpy road', \n",
    "            23:'Slippery road', \n",
    "            24:'Road narrows on the right', \n",
    "            25:'Road work', \n",
    "            26:'Traffic signals', \n",
    "            27:'Pedestrians', \n",
    "            28:'Children crossing', \n",
    "            29:'Bicycles crossing', \n",
    "            30:'Beware of ice/snow',\n",
    "            31:'Wild animals crossing', \n",
    "            32:'End speed + passing limits', \n",
    "            33:'Turn right ahead', \n",
    "            34:'Turn left ahead', \n",
    "            35:'Ahead only', \n",
    "            36:'Go straight or right', \n",
    "            37:'Go straight or left', \n",
    "            38:'Keep right', \n",
    "            39:'Keep left', \n",
    "            40:'Roundabout mandatory', \n",
    "            41:'End of no passing', \n",
    "            42:'End no passing veh > 3.5 tons' }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fba3e9f-9a8c-4539-97c4-5324515bd86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 48, 48, 16)        448       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 46, 46, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 23, 23, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 23, 23, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 19, 19, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 9, 9, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 9, 9, 128)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 10368)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               5308928   \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 43)                22059     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5428427 (20.71 MB)\n",
      "Trainable params: 5428427 (20.71 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('trafficSignModel.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "090c07dc-ff9f-4758-96f1-771a5b765df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = pd.read_csv('Test.csv')\n",
    "test_images = Y_test[\"Path\"].values\n",
    "test_labels = Y_test[\"ClassId\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb9b19e9-3ffe-43a9-9e06-e5865ec5d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = list()\n",
    "for testImage in test_images:\n",
    "    if testImage.endswith(\".png\"):\n",
    "        pic = load_img(testImage, target_size=(50, 50))\n",
    "        output.append(np.array(pic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5da29e0-c085-44bb-b5d1-cb788cdda06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12630, 50, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "# convert training images into numpy array\n",
    "XTest=np.array(output)\n",
    "\n",
    "print(XTest.shape)\n",
    "# pixel values range between 0-255. Divide each array by 255 to normalize\n",
    "#testImages = testImages/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "377c7fce-ae8c-49e1-aaf6-585d27efa80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(test_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81338a3a-e617-4082-866e-001eccb3849d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 5s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(testImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be2126c9-24a5-498b-88df-1404f061d5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12630\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd9a512d-7c78-463f-a682-c18e3bbb1998",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c981c00-fdd5-4856-9782-b67b4e9c430f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 14  2 ... 10  3  2]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0310cd8-c1ce-46ea-9c79-716ab6a4e8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data accuracy:  3.95882818685669\n"
     ]
    }
   ],
   "source": [
    "#Accuracy with the test data\n",
    "print('Test Data accuracy: ',accuracy_score(test_labels, predictions)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93429ecc-0bb4-430b-99da-b66786c29d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16  1 38 ...  6  7 10]\n"
     ]
    }
   ],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23c4541-8018-45e3-9bf3-c8065e3374df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
